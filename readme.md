# âš–ï¸ LegalPrasna AI Chatbot

A **Retrieval-Augmented Generation (RAG)** based chatbot for answering legal questions, powered by:

- ğŸ§  **Infinity VectorDB** (by Infiniflow) for fast vector search
- ğŸ§¾ Gemmini or LLM backend for completions

---

![Chatbot Demo](assests/chatbot_screenshot.png)
---

## ğŸ“¦ Features

- Fast, local vector search with **Infinity**
- Semantic search on legal documents
- Chat interface with context-aware Q&A
- Plug-and-play config using TOML
- Easy deployment on AWS EC2

---

## ğŸ§° Prerequisites

### Hardware
- âœ… Minimum: `t3.medium` EC2 instance (2 vCPU, 4GB RAM)
- âŒ Not suitable for `t3.micro`

### Software
- Python 3.10+
- Docker (optional)
- Ubuntu 20.04/22.04 or Amazon Linux 2

---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/zokkomon/quest_rag.git
cd quest_rag
````

### 2. Create a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```
---

## ğŸ”Œ Running Infinity VectorDB

### 1. Download and extract Infinity

```bash
wget https://github.com/infiniflow/infinity/releases/download/v0.6.0/infinity-linux-amd64.tar.gz
tar -xvf infinity-linux-amd64.tar.gz
cd infinity
```

### 2. Create config file

Create `conf/pytest_embedded_infinity_conf.toml`:

```toml
[general]
version = "0.6.0"
time_zone = "utc-8"

[network]
server_address = "0.0.0.0"
http_port = 23820
peer_ip = "0.0.0.0"
peer_port = 23850

[log]
log_filename = "infinity.log"
log_dir = "/var/infinity/log"
log_to_stdout = true
log_level = "info"

[storage]
persistence_dir = "/var/infinity/persistence"

[buffer]
buffer_manager_size = "128MB"
temp_dir = "/var/infinity/tmp"

[wal]
wal_dir = "/var/infinity/wal"

[resource]
resource_dir = "/var/infinity/resource"

[performance]
memindex_memory_quota = "256MB"
dense_index_building_worker = 1
sparse_index_building_worker = 1
fulltext_index_building_worker = 1
```

Ensure required directories exist:

```bash
sudo mkdir -p /var/infinity/{log,persistence,tmp,wal,resource,data,snapshot}
sudo chmod -R 777 /var/infinity/
```

### 3. Run Infinity
---

## ğŸ’» Running Project

```bash
cd quest_rag
source venv/bin/activate (for linux)
python app.py
```

---

## ğŸŒ Accessing the App

* **Chatbot UI**: `http://localhost:5000`

---

## ğŸ³ Optional: Docker Deployment

Coming soon.

---

## ğŸ“‚ Project Structure

```
quest_rag/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ Home.py
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ pytest_embedded_infinity_conf.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ assets/
    â””â”€â”€ chatbot_screenshot.png
```

---

## ğŸ› ï¸ Troubleshooting

* **Crash on t3.micro**: Use a bigger instance like `t3.medium`.
* **Config not found**: Ensure your TOML file is in the correct location.
* **Memory issues**: Reduce `memindex_memory_quota` and buffer sizes in the config.

---

## ğŸ¤ Credits

* [Infiniflow Infinity VectorDB](https://github.com/infiniflow/infinity)
* [OpenAI Embedding models](https://platform.openai.com)

---

## ğŸ“œ License

MIT License
